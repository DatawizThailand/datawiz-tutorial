{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mIWbiNOsy4cj"
   },
   "source": [
    "# Simple Thai Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HiHhGmN_yw-E"
   },
   "outputs": [],
   "source": [
    "text_list = [    \n",
    "    '''\n",
    "    เฟ็ดเฟ่อย่างกับเดอะค็อป 999 (คลิป) <br>\n",
    "    #ข่าวสด #เด่นออนไลน์ <br>\n",
    "    รีบดูก่อนโดนลบ! เฟ็ดเฟ่สร้างความฮึกเฮิม นั่งหลังคารถชูถ้วยจุดพลุ มั่นใจมาแน่นอน <br>\n",
    "    บิวด์กันเข้าไป ก่อนเกมการแข่งขัน ยูฟ่าแชมเปียนส์ลีก รอบ … <br>\n",
    "    <img src='https://xxx'>\n",
    "    ''',\n",
    "             \n",
    "    '''\n",
    "    แอดขอให้คุณผู้อ่านใช้วิจารณญาณและดุลยพินิจในการอ่าน \n",
    "    คำพูดที่สอบถามคุณยายเป็นเพียงความข้างเดียวที่ออกมาจากใจและปากของคุณยาย \n",
    "    ยังไม่มีโอกาสไปสอบถามความ อีกมุมจากตัวลูกชายคนเล็ก #แม่เฒ่าถูกไล่ #แม่เฒ่าขาพิการ #พาหลานชายพิการนอนข้างทาง <br>\n",
    "    'อย่าว่าเขาๆคงมีเหตุผล' 'ยาย'ถูก'ลูก'ไล่-ขอร้องแม้ปวดใจ <br>\n",
    "    ประชาชนที่รู้ข่าวต่างนำอาหารกับน้ำดื่ม ไปให้ 2 ยายหลานผู้พิการได้ดื่มกิน หลังถูกลูกชายไล่จนต้องนอนศาลาร.... <br>\n",
    "    <img src='https://xxx'>\n",
    "    '''\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uNJnNAUE9UOe"
   },
   "source": [
    "## Step 1: Text cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7DLBXasQ2KW7"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "def clean_msg(msg):\n",
    "    \n",
    "    \n",
    "    # ลบ text ที่อยู่ในวงเล็บ <> ทั้งหมด\n",
    "    msg = re.sub(r'<.*?>','', msg)\n",
    "    \n",
    "    # ลบ hashtag\n",
    "    msg = re.sub(r'#','',msg)\n",
    "    \n",
    "    # ลบ เครื่องหมายคำพูด (punctuation)\n",
    "    for c in string.punctuation:\n",
    "        msg = re.sub(r'\\{}'.format(c),'',msg)\n",
    "    \n",
    "    # ลบ separator เช่น \\n \\t\n",
    "    msg = ' '.join(msg.split())\n",
    "    \n",
    "    return msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "cAqZE1H92fLY",
    "outputId": "6c722dc3-48c1-4993-e18d-d7291469071e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original text:\n",
      "\n",
      "    เฟ็ดเฟ่อย่างกับเดอะค็อป 999 (คลิป) <br>\n",
      "    #ข่าวสด #เด่นออนไลน์ <br>\n",
      "    รีบดูก่อนโดนลบ! เฟ็ดเฟ่สร้างความฮึกเฮิม นั่งหลังคารถชูถ้วยจุดพลุ มั่นใจมาแน่นอน <br>\n",
      "    บิวด์กันเข้าไป ก่อนเกมการแข่งขัน ยูฟ่าแชมเปียนส์ลีก รอบ … <br>\n",
      "    <img src='https://xxx'>\n",
      "    \n",
      "clean text:\n",
      "\n",
      "เฟ็ดเฟ่อย่างกับเดอะค็อป 999 คลิป ข่าวสด เด่นออนไลน์ รีบดูก่อนโดนลบ เฟ็ดเฟ่สร้างความฮึกเฮิม นั่งหลังคารถชูถ้วยจุดพลุ มั่นใจมาแน่นอน บิวด์กันเข้าไป ก่อนเกมการแข่งขัน ยูฟ่าแชมเปียนส์ลีก รอบ …\n"
     ]
    }
   ],
   "source": [
    "print('original text:\\n'+text_list[0])\n",
    "print('clean text:\\n\\n'+clean_msg(text_list[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "TXzjQ3fj2iWY",
    "outputId": "a5dd32e1-1089-4d42-83ef-45c28a060e82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original text:\n",
      "\n",
      "    แอดขอให้คุณผู้อ่านใช้วิจารณญาณและดุลยพินิจในการอ่าน \n",
      "    คำพูดที่สอบถามคุณยายเป็นเพียงความข้างเดียวที่ออกมาจากใจและปากของคุณยาย \n",
      "    ยังไม่มีโอกาสไปสอบถามความ อีกมุมจากตัวลูกชายคนเล็ก #แม่เฒ่าถูกไล่ #แม่เฒ่าขาพิการ #พาหลานชายพิการนอนข้างทาง <br>\n",
      "    'อย่าว่าเขาๆคงมีเหตุผล' 'ยาย'ถูก'ลูก'ไล่-ขอร้องแม้ปวดใจ <br>\n",
      "    ประชาชนที่รู้ข่าวต่างนำอาหารกับน้ำดื่ม ไปให้ 2 ยายหลานผู้พิการได้ดื่มกิน หลังถูกลูกชายไล่จนต้องนอนศาลาร.... <br>\n",
      "    <img src='https://xxx'>\n",
      "    \n",
      "clean text:\n",
      "\n",
      "แอดขอให้คุณผู้อ่านใช้วิจารณญาณและดุลยพินิจในการอ่าน คำพูดที่สอบถามคุณยายเป็นเพียงความข้างเดียวที่ออกมาจากใจและปากของคุณยาย ยังไม่มีโอกาสไปสอบถามความ อีกมุมจากตัวลูกชายคนเล็ก แม่เฒ่าถูกไล่ แม่เฒ่าขาพิการ พาหลานชายพิการนอนข้างทาง อย่าว่าเขาๆคงมีเหตุผล ยายถูกลูกไล่ขอร้องแม้ปวดใจ ประชาชนที่รู้ข่าวต่างนำอาหารกับน้ำดื่ม ไปให้ 2 ยายหลานผู้พิการได้ดื่มกิน หลังถูกลูกชายไล่จนต้องนอนศาลาร\n"
     ]
    }
   ],
   "source": [
    "print('original text:\\n'+text_list[1])\n",
    "print('clean text:\\n\\n'+clean_msg(text_list[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XM4tAaU2Gxf-"
   },
   "outputs": [],
   "source": [
    "clean_text = [clean_msg(txt) for txt in text_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HMsJiL3-_4p5"
   },
   "source": [
    "## Step 2: Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pythainlp --user\n",
    "!pip install stop_words --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 700
    },
    "colab_type": "code",
    "id": "nd_Ssn4S_cLf",
    "outputId": "a5fa2bd8-49cd-4c28-8f9f-03a37b528ebf"
   },
   "outputs": [],
   "source": [
    "import pythainlp\n",
    "\n",
    "from pythainlp import word_tokenize\n",
    "from pythainlp.corpus import stopwords\n",
    "from pythainlp.corpus import wordnet\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import words\n",
    "from stop_words import get_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('words')\n",
    "\n",
    "th_stop = tuple(stopwords.words('thai'))\n",
    "en_stop = tuple(get_stop_words('en'))\n",
    "p_stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L0PE6j5gAk2O"
   },
   "outputs": [],
   "source": [
    "def split_word(text):\n",
    "            \n",
    "    \n",
    "    tokens = word_tokenize(text,engine='newmm')\n",
    "    \n",
    "    # Remove stop words ภาษาไทย และภาษาอังกฤษ\n",
    "    tokens = [i for i in tokens if not i in th_stop and not i in en_stop]\n",
    "    \n",
    "    # หารากศัพท์ภาษาไทย และภาษาอังกฤษ\n",
    "    # English\n",
    "    tokens = [p_stemmer.stem(i) for i in tokens]\n",
    "    \n",
    "    # Thai\n",
    "    tokens_temp=[]\n",
    "    for i in tokens:\n",
    "        w_syn = wordnet.synsets(i)\n",
    "        if (len(w_syn)>0) and (len(w_syn[0].lemma_names('tha'))>0):\n",
    "            tokens_temp.append(w_syn[0].lemma_names('tha')[0])\n",
    "        else:\n",
    "            tokens_temp.append(i)\n",
    "    \n",
    "    tokens = tokens_temp\n",
    "    \n",
    "    # ลบตัวเลข\n",
    "    tokens = [i for i in tokens if not i.isnumeric()]\n",
    "    \n",
    "    # ลบช่องว่าง\n",
    "    tokens = [i for i in tokens if not ' ' in i]\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "Ncd6qBzeCtDD",
    "outputId": "fe6ec4cc-9ccd-4196-fcff-d2ac7891d326"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenized text:\n",
      "\n",
      "['เฟ็ด', 'เฟ่', 'เดอะ', 'ค็อป', 'คลิป', 'ข่าวสด', 'เด่น', 'ออนไลน์', 'รีบ', 'ดูก่อน', 'โดน', 'ลบ', 'เฟ็ด', 'เฟ่', 'สร้าง', 'ฮึก', 'เฮิม', 'นั่ง', 'หลังคา', 'รถ', 'ชู', 'ถ้วย', 'จุด', 'พลุ', 'มั่น', 'ใจมา', 'แน่นอน', 'บิ', 'วด์', 'เข้าไป', 'เกม', 'การแข่งขัน', 'ยูฟ่า', 'แชมเปียนส์', 'ลีก', 'รอบ', '…']\n",
      "\n",
      "tokenized text:\n",
      "\n",
      "['แอด', 'ขอให้', 'คนอ่าน', 'วิจารณญาณ', 'ดุลยพินิจ', 'อ่าน', 'คำพูด', 'สอบถาม', 'ยาย', 'ข้างเดียว', 'มาจาก', 'ใจ', 'ปาก', 'ยาย', 'มีโอกาส', 'สอบถาม', 'มุม', 'ตัว', 'โอรส', 'คน', 'ยาย', 'ไล่', 'ยาย', 'ขา', 'พิการ', 'หลานชาย', 'พิการ', 'นอน', 'ข้างทาง', 'อย่า', 'ๆคง', 'มีเหตุผล', 'ยาย', 'ลูกไล่', 'ขอร้อง', 'ปวดใจ', 'ปชช.', 'รู้', 'ข่าว', 'อาหาร', 'น้ำ', 'ยาย', 'หลาน', 'พิการ', 'กิน', 'กิน', 'โอรส', 'ไล่', 'นอน', 'ศาลา', 'ร']\n"
     ]
    }
   ],
   "source": [
    "print('tokenized text:\\n')\n",
    "print(split_word(clean_msg(text_list[0])))\n",
    "print('\\ntokenized text:\\n')\n",
    "print(split_word(clean_msg(text_list[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_E6wussDHCkm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['เฟ็ด', 'เฟ่', 'เดอะ', 'ค็อป', 'คลิป', 'ข่าวสด', 'เด่น', 'ออนไลน์', 'รีบ', 'ดูก่อน', 'โดน', 'ลบ', 'เฟ็ด', 'เฟ่', 'สร้าง', 'ฮึก', 'เฮิม', 'นั่ง', 'หลังคา', 'รถ', 'ชู', 'ถ้วย', 'จุด', 'พลุ', 'มั่น', 'ใจมา', 'แน่นอน', 'บิ', 'วด์', 'เข้าไป', 'เกม', 'การแข่งขัน', 'ยูฟ่า', 'แชมเปียนส์', 'ลีก', 'รอบ', '…'], ['แอด', 'ขอให้', 'คนอ่าน', 'วิจารณญาณ', 'ดุลยพินิจ', 'อ่าน', 'คำพูด', 'สอบถาม', 'ยาย', 'ข้างเดียว', 'มาจาก', 'ใจ', 'ปาก', 'ยาย', 'มีโอกาส', 'สอบถาม', 'มุม', 'ตัว', 'โอรส', 'คน', 'ยาย', 'ไล่', 'ยาย', 'ขา', 'พิการ', 'หลานชาย', 'พิการ', 'นอน', 'ข้างทาง', 'อย่า', 'ๆคง', 'มีเหตุผล', 'ยาย', 'ลูกไล่', 'ขอร้อง', 'ปวดใจ', 'ปชช.', 'รู้', 'ข่าว', 'อาหาร', 'น้ำ', 'ยาย', 'หลาน', 'พิการ', 'กิน', 'กิน', 'โอรส', 'ไล่', 'นอน', 'ศาลา', 'ร']]\n"
     ]
    }
   ],
   "source": [
    "tokens_list = [split_word(txt) for txt in clean_text]\n",
    "print(tokens_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5xyaFdoLF-bm"
   },
   "source": [
    "## Step 3a: Bag of words + Word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KacGNWcMjzrn"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'การแข่งขัน': 0,\n",
       " 'กิน': 1,\n",
       " 'ขอร้อง': 2,\n",
       " 'ขอให้': 3,\n",
       " 'ขา': 4,\n",
       " 'ข่าว': 5,\n",
       " 'ข่าวสด': 6,\n",
       " 'ข้างทาง': 7,\n",
       " 'ข้างเดียว': 8,\n",
       " 'คน': 9,\n",
       " 'คนอ่าน': 10,\n",
       " 'คลิป': 11,\n",
       " 'คำพูด': 12,\n",
       " 'ค็อป': 13,\n",
       " 'จุด': 14,\n",
       " 'ชู': 15,\n",
       " 'ดุลยพินิจ': 16,\n",
       " 'ดูก่อน': 17,\n",
       " 'ตัว': 18,\n",
       " 'ถ้วย': 19,\n",
       " 'นอน': 20,\n",
       " 'นั่ง': 21,\n",
       " 'น้ำ': 22,\n",
       " 'บิ': 23,\n",
       " 'ปชช.': 24,\n",
       " 'ปวดใจ': 25,\n",
       " 'ปาก': 26,\n",
       " 'พลุ': 27,\n",
       " 'พิการ': 28,\n",
       " 'มั่น': 29,\n",
       " 'มาจาก': 30,\n",
       " 'มีเหตุผล': 31,\n",
       " 'มีโอกาส': 32,\n",
       " 'มุม': 33,\n",
       " 'ยาย': 34,\n",
       " 'ยูฟ่า': 35,\n",
       " 'ร': 36,\n",
       " 'รถ': 37,\n",
       " 'รอบ': 38,\n",
       " 'รีบ': 39,\n",
       " 'รู้': 40,\n",
       " 'ลบ': 41,\n",
       " 'ลีก': 42,\n",
       " 'ลูกไล่': 43,\n",
       " 'วด์': 44,\n",
       " 'วิจารณญาณ': 45,\n",
       " 'ศาลา': 46,\n",
       " 'สร้าง': 47,\n",
       " 'สอบถาม': 48,\n",
       " 'หลังคา': 49,\n",
       " 'หลาน': 50,\n",
       " 'หลานชาย': 51,\n",
       " 'อย่า': 52,\n",
       " 'ออนไลน์': 53,\n",
       " 'อาหาร': 54,\n",
       " 'อ่าน': 55,\n",
       " 'ฮึก': 56,\n",
       " 'เกม': 57,\n",
       " 'เข้าไป': 58,\n",
       " 'เดอะ': 59,\n",
       " 'เด่น': 60,\n",
       " 'เฟ็ด': 61,\n",
       " 'เฟ่': 62,\n",
       " 'เฮิม': 63,\n",
       " 'แชมเปียนส์': 64,\n",
       " 'แน่นอน': 65,\n",
       " 'แอด': 66,\n",
       " 'โดน': 67,\n",
       " 'โอรส': 68,\n",
       " 'ใจ': 69,\n",
       " 'ใจมา': 70,\n",
       " 'ไล่': 71,\n",
       " 'ๆคง': 72,\n",
       " '…': 73}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "tokens_list_j = [','.join(tkn) for tkn in tokens_list]\n",
    "cvec = CountVectorizer(analyzer=lambda x:x.split(','))\n",
    "c_feat = cvec.fit_transform(tokens_list_j)\n",
    "\n",
    "cvec.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "MCfZP-NMb0lM",
    "outputId": "88efc12b-2d21-4c8d-bec4-16da347ee730"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1],\n",
       "        [0, 2, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_feat[:,:20].todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nmOB-4XYp5FM"
   },
   "source": [
    "## Step 3b: Bag of words + tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3BGXh4AIiVIg"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tvec = TfidfVectorizer(analyzer=lambda x:x.split(','),)\n",
    "t_feat = tvec.fit_transform(tokens_list_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "FXpAGrHaqLAg",
    "outputId": "fb8f31f5-ce95-4eea-dfe7-77727395d327"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.15617376, 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.20306923, 0.10153462, 0.10153462, 0.10153462]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_feat[:,:5].todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "94JnkQ1CqMnO",
    "outputId": "14393151-f48c-4150-e898-426559d99497"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74 74\n"
     ]
    }
   ],
   "source": [
    "print(len(tvec.idf_),len(tvec.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "xNr2NEFwpZ6r",
    "outputId": "489efce1-2e26-462d-90a7-06e7d0ead8e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 0, 0, 0, 0],\n",
       "        [0, 2, 1, 1, 1]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_feat[:,:5].todense()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "1) Simple Thai text preprocessing.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
